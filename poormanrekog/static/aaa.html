<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />
    <title>Poor man's Rekog</title>
  </head>
  <body>
    <h1 id="poormansrekognition">Poor man's Rekognition</h1>

    <p>
      Open source alternative to Amazon Rekognition offered by AWS. Currently,
      can identify 1081 clebrity faces. <br />
      Uses deep metric learning instead of deep learning for face identificaton.
    </p>

    <h2 id="quicksetup">Quick setup</h2>

    <ol>
      <li>create virtual env, install requirements</li>

      <li>Run flask server (<code>python driver.py</code>)</li>

      <li>This is a REST application. Fire up POSTMAN</li>
    </ol>

    <h3 id="routedescriptions">Route descriptions</h3>

    <pre><code>POST /recogniseFaces
</code></pre>

    <p>
      (Set form type to be form-data) <br />
      params::
    </p>

    <p>
      <code>"image": (The__image_file)</code> [Choose 'file' in the drop down
      that appears besides the key input field][or] <br />
      <code>"video": (The_video_file)</code> [Attach the video file]
    </p>

    <p>(Note): If both parameters are set, only the image is processed.</p>

    <p>
      Return values: <br />
      In case of an image, a JSON string will likeliness of each face is
      returned. <br />
      In case of a video, a JSON string indicating the result is returned.
    </p>

    <pre><code>GET /recogniseFaces
</code></pre>

    <p>
      (Returns the latest saved image/video) <br />
      params::
    </p>

    <p>
      <code>"image"</code> : If image parameter is set, then the latest
      processed image is returned. <br />
      [OR] <br />
      <code>"video"</code> : If video parameter is set, then the latest
      processed video is returned.
    </p>

    <p>
      (Note): If both parameters are set, only the image is returned. This
      returns the processed image.(A label for each bounded box for each face.
      The descriptions of the label are returned through the post request).
    </p>

    <pre><code>GET  /names
</code></pre>

    <p>(no params)</p>

    <p>
      Return values: A JSON string with the names of all celebrities that can be
      recognised
    </p>

    <pre><code>POST /feedback
</code></pre>

    <p>
      (Lets you tune the model with your feedback) <br />
      params::
    </p>

    <p>
      <code>"image" : (The_image_file)</code> [Choose 'file' in the drop down
      that appears besides the key input field. Put body type to be Form-data]
      <br />
      <code
        >"name" : (A String that has underscores instead of spaces and all
        small)</code
      >
      <br />
      (This is the name that you want the model to understand, as the person in
      the pic)
    </p>

    <p>
      (Note): Make sure you get the names of all people first before using the
      get route. That will help you fine tune already existing celebrity faces.
      <br />
      The model will predict with less confidence next time. The more images you
      give of a single person, the more the confidence turns in your favour.
    </p>

    <p>Return value: A JSON string indicating success or failure</p>

    <p>
      dataset accumulated using my
      <a href="https://github.com/gigatesseract/GImageScrape"
        >image scraping tool</a
      >
      <br />
      link to dataset:
      <a
        href="https://drive.google.com/open?id=1NpuNBH6FNwPTXpxxPZ-xbqh3YhowcbF5"
        >here</a
      >
      <br />
      link to input/output files:
      <a
        href="https://drive.google.com/open?id=1n7_gZiYdT1nfJMj-oUqMKrORQtMCle1v"
        >here</a
      >
    </p>

    <h6
      id="canrecognise1081ceberitiestrainedon21592imagesnamesaregiveninknown_celebritiestxt"
    >
      Can recognise 1081 ceberities, trained on 21592 images. (Names are given
      in known_celebrities.txt)
    </h6>

    <p>Have fun! :smiley: :smiley: :smiley:</p>
  </body>
</html>
